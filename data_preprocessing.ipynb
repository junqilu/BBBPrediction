{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "import pickle  # Local Python (3.8) is fine with this. If you're suing Google\n",
    "# colab, which uses a Python version of 3.6, you need to do import pickel5\n",
    "# as pickle\n",
    "import cloudpickle as cp\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from imblearn.under_sampling import RandomUnderSampler, ClusterCentroids\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collinearity import SelectNonCollinear\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR, SVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, \\\n",
    "    StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, \\\n",
    "    r2_score, make_scorer, recall_score, accuracy_score, f1_score, \\\n",
    "    precision_score, balanced_accuracy_score, roc_curve, auc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Custom functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to find the pandas get_adjustment() function to patch\n",
      "Failed to patch pandas - PandasTools will have limited functionality\n"
     ]
    }
   ],
   "source": [
    "from dataset_expansion import dataset_feature_expansion, merge_multiple_dfs\n",
    "from dataset_cleanup import filter_low_variance\n",
    "from dataset_plot import simple_pie_plot\n",
    "from pickle_managment import save_pickle, load_pickle\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert and clean .tsv files to .csv files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regression_tsv = 'datasets\\original_datasets\\B3DB_regression.tsv'\n",
    "regression_df = read_tsv_to_df(regression_tsv)\n",
    "regression_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regression_df_cleaned = regression_df[\n",
    "    [\n",
    "        'SMILES',\n",
    "        'logBB'\n",
    "    ]\n",
    "]\n",
    "\n",
    "regression_df_cleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regression_df_cleaned.to_csv(\n",
    "    'datasets\\cleaned_datasets\\BBB_regression.csv',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print('Done!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_tsv = 'datasets\\original_datasets\\B3DB_classification.tsv'\n",
    "classification_df = read_tsv_to_df(classification_tsv)\n",
    "classification_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_df_cleaned = classification_df[\n",
    "    [\n",
    "        'SMILES',\n",
    "        'BBB+/BBB-'\n",
    "    ]\n",
    "]\n",
    "\n",
    "classification_df_cleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_df_cleaned.to_csv(\n",
    "    'datasets\\cleaned_datasets\\BBB_classification.csv',\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print('Done!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read in data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regression_df = pd.read_csv('datasets\\cleaned_datasets\\BBB_regression.csv')\n",
    "regression_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(regression_df['logBB'] <= -1.01).sum()  #These are BBB-"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(regression_df['logBB'] >= -1).sum()  #These are BBB+"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_df = pd.read_csv(\n",
    "    'datasets\\cleaned_datasets\\BBB_classification.csv'\n",
    ")\n",
    "classification_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_df['BBB+/BBB-'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset expansion & cleaning\n",
    "Major expansion steps:\n",
    "1. Add in RDKit descriptors\n",
    "2. Add in Morgan fingerprints\n",
    "3. Add in MACCS keys\n",
    "\n",
    "Major cleaning steps:\n",
    "1. Remove columns whose variance is 0--all values are hte same\n",
    "    * Done by a function so later the threshold for filtering\n",
    "    based on variance level is adjustable"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regression_df_expanded, regression_expansion_errors = dataset_feature_expansion(\n",
    "    regression_df)\n",
    "regression_df_expanded  #Missing SMILES are the chemicals that have errors\n",
    "# when going through the calculations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regression_df_expanded_cleaned = filter_low_variance(\n",
    "    regression_df_expanded,\n",
    "    exclude_col_list=['SMILES', 'logBB'],\n",
    "    threshold_level=0\n",
    ")\n",
    "regression_df_expanded_cleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regression_df_expanded_cleaned.to_csv(\n",
    "    'datasets\\expanded_datasets\\BBB_regression_expanded.csv.zip',\n",
    "    index=False,\n",
    "    compression='zip'  # Have to use zip here since the classification\n",
    "    # dataset will become very large. Zipped .csv files can be directly read\n",
    "    # by pd.read_csv()\n",
    ")\n",
    "print('Done!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_df_expanded, classification_expansion_errors = dataset_feature_expansion(\n",
    "    classification_df)\n",
    "classification_df_expanded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_df_expanded_cleaned = filter_low_variance(\n",
    "    classification_df_expanded,\n",
    "    exclude_col_list=['SMILES', 'BBB+/BBB-'],\n",
    "    threshold_level=0\n",
    ")\n",
    "classification_df_expanded_cleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_df_expanded_cleaned.to_csv(\n",
    "    'datasets\\expanded_datasets\\BBB_classification_expanded.csv.zip',\n",
    "    index=False,\n",
    "    compression='zip'\n",
    ")\n",
    "print('Done!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset rebalance\n",
    "Before center and standardization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regression\n",
    "Regression dataset doesn't need rebalancing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_df_expanded_cleaned = pd.read_csv(\n",
    "    'datasets\\expanded_datasets\\BBB_classification_expanded.csv.zip')\n",
    "classification_df_expanded_cleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_BBB_N = (classification_df_expanded_cleaned\n",
    "[classification_df_expanded_cleaned['BBB+/BBB-'] == 'BBB-']).shape[0]  #These\n",
    "# are BBB-\n",
    "classification_BBB_Y = (classification_df_expanded_cleaned\n",
    "[classification_df_expanded_cleaned['BBB+/BBB-'] == 'BBB+']).shape[0]  #These\n",
    "# are BBB+\n",
    "\n",
    "simple_pie_plot(\n",
    "    label_list=['BBB-', 'BBB+'],\n",
    "    num_list=[classification_BBB_N, classification_BBB_Y],\n",
    "    title_str='Composition of 2 categories in regression dataset before balancing'\n",
    ")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = classification_df_expanded_cleaned.loc[\n",
    "    :,\n",
    "    ~classification_df_expanded_cleaned.columns.isin(['SMILES', 'BBB+/BBB-'])\n",
    "    ]\n",
    "y = classification_df_expanded_cleaned['BBB+/BBB-']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Under-sampling by ClusterCentroids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster_centroids = ClusterCentroids(\n",
    "    estimator=MiniBatchKMeans(n_init=1, random_state=1),\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "X_resample, y_resample = cluster_centroids.fit_resample(X, y)\n",
    "\n",
    "classification_df_after_centroid_balancing = merge_multiple_dfs(\n",
    "    df_list=[classification_df_expanded_cleaned['SMILES'], y_resample,\n",
    "             X_resample])\n",
    "classification_df_after_centroid_balancing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_BBB_N = (classification_df_after_centroid_balancing\n",
    "[classification_df_after_centroid_balancing['BBB+/BBB-'] == 'BBB-']).shape[\n",
    "    0]  #These\n",
    "# are BBB-\n",
    "classification_BBB_Y = (classification_df_after_centroid_balancing\n",
    "[classification_df_after_centroid_balancing['BBB+/BBB-'] == 'BBB+']).shape[\n",
    "    0]  #These\n",
    "# are BBB+\n",
    "\n",
    "simple_pie_plot(\n",
    "    label_list=['BBB-', 'BBB+'],\n",
    "    num_list=[classification_BBB_N, classification_BBB_Y],\n",
    "    title_str='Composition of 2 categories in regression dataset after '\n",
    "              'balancing by centroids method'\n",
    ")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_df_after_centroid_balancing.to_csv(\n",
    "    r'datasets\\balanced_datasets\\BBB_classification_balanced_centroid.csv.zip',\n",
    "    index=False,\n",
    "    compression='zip'\n",
    ")\n",
    "print('Done!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Over-sample by SMOTE then cleaning using ENN\n",
    "Not using SMOTE only to create lots of hypothetical chemicals that might\n",
    "not exist"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "smoteenn = SMOTEENN(random_state=1)\n",
    "\n",
    "X_resample, y_resample = smoteenn.fit_resample(X, y)\n",
    "\n",
    "classification_df_after_smoteenn_balancing = merge_multiple_dfs(\n",
    "    df_list=[classification_df_expanded_cleaned['SMILES'], y_resample,\n",
    "             X_resample])\n",
    "classification_df_after_smoteenn_balancing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_BBB_N = (classification_df_after_smoteenn_balancing\n",
    "[classification_df_after_smoteenn_balancing['BBB+/BBB-'] == 'BBB-']).shape[\n",
    "    0]  #These\n",
    "# are BBB-\n",
    "classification_BBB_Y = (classification_df_after_smoteenn_balancing\n",
    "[classification_df_after_smoteenn_balancing['BBB+/BBB-'] == 'BBB+']).shape[\n",
    "    0]  #These\n",
    "# are BBB+\n",
    "\n",
    "simple_pie_plot(\n",
    "    label_list=['BBB-', 'BBB+'],\n",
    "    num_list=[classification_BBB_N, classification_BBB_Y],\n",
    "    title_str='Composition of 2 categories in regression dataset after '\n",
    "              'balancing by SMOTE-ENN method'\n",
    ")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_df_after_smoteenn_balancing.to_csv(\n",
    "    r'datasets\\balanced_datasets\\BBB_classification_balanced_smoteenn.csv.zip',\n",
    "    index=False,\n",
    "    compression='zip'\n",
    ")\n",
    "print('Done!')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
