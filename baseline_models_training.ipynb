{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR, SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, \\\n",
    "    RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, \\\n",
    "    r2_score, make_scorer, recall_score, accuracy_score, f1_score, \\\n",
    "    precision_score, balanced_accuracy_score, roc_curve, auc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Custom functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to find the pandas get_adjustment() function to patch\n",
      "Failed to patch pandas - PandasTools will have limited functionality\n"
     ]
    }
   ],
   "source": [
    "from pickle_managment import save_pickle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 SMILES  logBB  \\\n0     CN1C(=NN=N1)SCC2=C(N3C(C(C3=O)(NC(=O)C(C4=CC=C...  -2.52   \n1     CN1CC[C@]23[C@@H]4[C@H]1CC5=C2C(=C(C=C5)OC6[C@...  -2.15   \n2     CN1CC[C@]23[C@@H]4[C@H]1CC5=C2C(=C(C=C5)O)O[C@...  -2.09   \n3      CC1=NC=C(C=C1)CC2CNC(NC2=O)NCCCCC3=NC=C(C=C3C)Br  -1.88   \n4     c1(c2c3n(c4c(C(N(C)C3)=O)c(Cl)ccc4)cn2)noc(C(O...  -1.82   \n...                                                 ...    ...   \n1046              C[NH2+]CCCN1C2=CC=CC=C2CCC3=CC=CC=C31   1.20   \n1047                 CN(C)CCCN1C2=CC=CC=C2SC3=CC=CC=C31   1.23   \n1048                  CN(C)CCOC(C1=CC=CC=C1)C2=CC=CC=C2   1.30   \n1049                CNCCCN1C2=CC=CC=C2SC3=C1C=C(C=C3)Cl   1.40   \n1050   CN[C@H]1CC[C@H](C2=CC=CC=C12)C3=CC(=C(C=C3)Cl)Cl   1.60   \n\n      MaxAbsEStateIndex  MaxEStateIndex  MinAbsEStateIndex  MinEStateIndex  \\\n0             13.190522       13.190522           0.042537       -2.144257   \n1             11.445328       11.445328           0.165306       -1.798901   \n2             11.479044       11.479044           0.060963       -1.790095   \n3             12.391214       12.391214           0.061101       -0.159783   \n4             12.699094       12.699094           0.092039       -2.255140   \n...                 ...             ...                ...             ...   \n1046           2.515046        2.515046           1.095602        1.095602   \n1047           2.462963        2.462963           1.062269        1.062269   \n1048           6.083380        6.083380           0.016065        0.016065   \n1049           6.182100        6.182100           0.793840        0.793840   \n1050           6.171803        6.171803           0.407932        0.407932   \n\n           qed        SPS    MolWt  HeavyAtomMolWt  ...  157_y  158_y  159_y  \\\n0     0.133795  22.000000  520.480         500.320  ...    1.0    1.0    1.0   \n1     0.346256  45.303030  461.467         434.251  ...    1.0    1.0    1.0   \n2     0.359144  45.393939  461.467         434.251  ...    1.0    1.0    1.0   \n3     0.543803  19.464286  446.393         418.169  ...    0.0    1.0    0.0   \n4     0.648321  14.192308  375.772         361.660  ...    1.0    1.0    1.0   \n...        ...        ...      ...             ...  ...    ...    ...    ...   \n1046  0.843816  13.550000  267.396         244.212  ...    0.0    1.0    0.0   \n1047  0.828858  13.250000  284.428         264.268  ...    0.0    1.0    0.0   \n1048  0.784550  11.157895  255.361         234.193  ...    1.0    1.0    0.0   \n1049  0.834133  13.000000  304.846         287.710  ...    0.0    1.0    0.0   \n1050  0.805861  21.550000  306.236         289.100  ...    0.0    1.0    0.0   \n\n      160_y  161_y  162_y  163_y  164_y  165_y  166_y  \n0       1.0    1.0    1.0    1.0    1.0    1.0    0.0  \n1       1.0    1.0    1.0    1.0    1.0    1.0    0.0  \n2       1.0    1.0    1.0    1.0    1.0    1.0    0.0  \n3       1.0    1.0    1.0    1.0    1.0    1.0    0.0  \n4       1.0    1.0    1.0    1.0    1.0    1.0    0.0  \n...     ...    ...    ...    ...    ...    ...    ...  \n1046    1.0    1.0    1.0    1.0    0.0    1.0    0.0  \n1047    1.0    1.0    1.0    1.0    0.0    1.0    0.0  \n1048    1.0    1.0    1.0    1.0    1.0    1.0    0.0  \n1049    1.0    1.0    1.0    1.0    0.0    1.0    0.0  \n1050    1.0    1.0    1.0    1.0    0.0    1.0    0.0  \n\n[1051 rows x 4103 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SMILES</th>\n      <th>logBB</th>\n      <th>MaxAbsEStateIndex</th>\n      <th>MaxEStateIndex</th>\n      <th>MinAbsEStateIndex</th>\n      <th>MinEStateIndex</th>\n      <th>qed</th>\n      <th>SPS</th>\n      <th>MolWt</th>\n      <th>HeavyAtomMolWt</th>\n      <th>...</th>\n      <th>157_y</th>\n      <th>158_y</th>\n      <th>159_y</th>\n      <th>160_y</th>\n      <th>161_y</th>\n      <th>162_y</th>\n      <th>163_y</th>\n      <th>164_y</th>\n      <th>165_y</th>\n      <th>166_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CN1C(=NN=N1)SCC2=C(N3C(C(C3=O)(NC(=O)C(C4=CC=C...</td>\n      <td>-2.52</td>\n      <td>13.190522</td>\n      <td>13.190522</td>\n      <td>0.042537</td>\n      <td>-2.144257</td>\n      <td>0.133795</td>\n      <td>22.000000</td>\n      <td>520.480</td>\n      <td>500.320</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CN1CC[C@]23[C@@H]4[C@H]1CC5=C2C(=C(C=C5)OC6[C@...</td>\n      <td>-2.15</td>\n      <td>11.445328</td>\n      <td>11.445328</td>\n      <td>0.165306</td>\n      <td>-1.798901</td>\n      <td>0.346256</td>\n      <td>45.303030</td>\n      <td>461.467</td>\n      <td>434.251</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CN1CC[C@]23[C@@H]4[C@H]1CC5=C2C(=C(C=C5)O)O[C@...</td>\n      <td>-2.09</td>\n      <td>11.479044</td>\n      <td>11.479044</td>\n      <td>0.060963</td>\n      <td>-1.790095</td>\n      <td>0.359144</td>\n      <td>45.393939</td>\n      <td>461.467</td>\n      <td>434.251</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CC1=NC=C(C=C1)CC2CNC(NC2=O)NCCCCC3=NC=C(C=C3C)Br</td>\n      <td>-1.88</td>\n      <td>12.391214</td>\n      <td>12.391214</td>\n      <td>0.061101</td>\n      <td>-0.159783</td>\n      <td>0.543803</td>\n      <td>19.464286</td>\n      <td>446.393</td>\n      <td>418.169</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>c1(c2c3n(c4c(C(N(C)C3)=O)c(Cl)ccc4)cn2)noc(C(O...</td>\n      <td>-1.82</td>\n      <td>12.699094</td>\n      <td>12.699094</td>\n      <td>0.092039</td>\n      <td>-2.255140</td>\n      <td>0.648321</td>\n      <td>14.192308</td>\n      <td>375.772</td>\n      <td>361.660</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1046</th>\n      <td>C[NH2+]CCCN1C2=CC=CC=C2CCC3=CC=CC=C31</td>\n      <td>1.20</td>\n      <td>2.515046</td>\n      <td>2.515046</td>\n      <td>1.095602</td>\n      <td>1.095602</td>\n      <td>0.843816</td>\n      <td>13.550000</td>\n      <td>267.396</td>\n      <td>244.212</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1047</th>\n      <td>CN(C)CCCN1C2=CC=CC=C2SC3=CC=CC=C31</td>\n      <td>1.23</td>\n      <td>2.462963</td>\n      <td>2.462963</td>\n      <td>1.062269</td>\n      <td>1.062269</td>\n      <td>0.828858</td>\n      <td>13.250000</td>\n      <td>284.428</td>\n      <td>264.268</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1048</th>\n      <td>CN(C)CCOC(C1=CC=CC=C1)C2=CC=CC=C2</td>\n      <td>1.30</td>\n      <td>6.083380</td>\n      <td>6.083380</td>\n      <td>0.016065</td>\n      <td>0.016065</td>\n      <td>0.784550</td>\n      <td>11.157895</td>\n      <td>255.361</td>\n      <td>234.193</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1049</th>\n      <td>CNCCCN1C2=CC=CC=C2SC3=C1C=C(C=C3)Cl</td>\n      <td>1.40</td>\n      <td>6.182100</td>\n      <td>6.182100</td>\n      <td>0.793840</td>\n      <td>0.793840</td>\n      <td>0.834133</td>\n      <td>13.000000</td>\n      <td>304.846</td>\n      <td>287.710</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1050</th>\n      <td>CN[C@H]1CC[C@H](C2=CC=CC=C12)C3=CC(=C(C=C3)Cl)Cl</td>\n      <td>1.60</td>\n      <td>6.171803</td>\n      <td>6.171803</td>\n      <td>0.407932</td>\n      <td>0.407932</td>\n      <td>0.805861</td>\n      <td>21.550000</td>\n      <td>306.236</td>\n      <td>289.100</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1051 rows Ã— 4103 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_df_expanded_cleaned = pd.read_csv(\n",
    "    'datasets\\expanded_datasets\\BBB_regression_expanded.csv.zip'\n",
    ")\n",
    "regression_df_expanded_cleaned"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "regression_X = regression_df_expanded_cleaned.loc[\n",
    "               :,\n",
    "               ~regression_df_expanded_cleaned.columns.isin(\n",
    "                   ['SMILES', 'logBB'])\n",
    "               ]\n",
    "\n",
    "regression_y = regression_df_expanded_cleaned['logBB']\n",
    "\n",
    "regression_X_train, regression_X_test, regression_y_train, regression_y_test = train_test_split(\n",
    "    regression_X,\n",
    "    regression_y,\n",
    "    test_size=0.2,\n",
    "    random_state=1,\n",
    "    shuffle=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "svr_model = SVR()\n",
    "\n",
    "svr_regressor_grid_search = GridSearchCV(\n",
    "    estimator=svr_model,\n",
    "    param_grid={\n",
    "        'kernel': ['rbf'],  #Kernel to solve with model, should try rbf, poly, and sigmoid\n",
    "        'gamma': [0.1, 0.5],  #Solver value important for rbf kernel\n",
    "        #'degree': [2,3,4] #Used for polynomial kernel\n",
    "        #'C': [0.001, 0.01, 0.1, 1, 10, 100] #Regularization parameter\n",
    "    },\n",
    "    cv=2,  #Number of fold for cross validation. It should be 8 or 10\n",
    "    scoring={\n",
    "        # All these are only viable in the negative option\n",
    "        'MAE': 'neg_mean_absolute_error',\n",
    "        'MSE': 'neg_mean_squared_error',\n",
    "        'R2': 'r2'\n",
    "    },\n",
    "    refit='R2',\n",
    "\n",
    "    n_jobs=1,\n",
    "    # -1 means using all processors, but it won't give you any messages.\n",
    "    # Only using 1 for my computer print out the training messages\n",
    "\n",
    "    verbose=10  #Provide detailed messages\n",
    ")\n",
    "\n",
    "svr_regressor_grid_search.fit(regression_X_train, regression_y_train)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('GridSearchCV took {}', end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svr_regressor_results_df = pd.DataFrame(svr_regressor_grid_search.cv_results_)\n",
    "#Make the GridSearch results into a df\n",
    "svr_regressor_results_df.drop(\n",
    "    list(svr_regressor_results_df.filter(regex='time|split|std')),\n",
    "    axis=1,\n",
    "    inplace=True\n",
    ")  # Remove columns that aren't very interesting\n",
    "\n",
    "svr_regressor_results_df = svr_regressor_results_df.sort_values(\n",
    "    by='rank_test_R2')\n",
    "svr_regressor_results_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svr_regressor_results_df.to_csv(\n",
    "    r'model_grid_search\\svr_regressor\\results.csv',\n",
    "    index=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_svr_regressor = svr_regressor_grid_search.best_estimator_\n",
    "save_pickle(\n",
    "    best_svr_regressor,\n",
    "    r'model_pickles\\svr_regressor\\best_svr_regressor.pkl'\n",
    ")\n",
    "# To load this best model again, use load_pickle(r'model_pickles\\svr_regressor\\best_rf_regressor.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model interpretation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Balanced by centroid method"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_centroid_df = pd.read_csv(\n",
    "    r\"datasets/balanced_datasets/BBB_classification_balanced_centroid.csv.zip\"\n",
    ")\n",
    "\n",
    "classification_centroid_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data pre-processing\n",
    "\n",
    "classification_X = classification_centroid_df.loc[\n",
    "                   :,\n",
    "                   ~classification_centroid_df.columns.isin(\n",
    "                       ['SMILES', 'BBB+/BBB-'])\n",
    "                   ]\n",
    "\n",
    "classification_y = classification_centroid_df['BBB+/BBB-']\n",
    "\n",
    "\n",
    "data_processing_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(\n",
    "        n_components=0.95, #When using the svd_solver='full', n_components\n",
    "        # can be between 0 and 1 to represent the percentage of variance\n",
    "        # that you want to explain\n",
    "        svd_solver='full'\n",
    "    ))\n",
    "])\n",
    "\n",
    "classification_X_processed=data_processing_pipeline.fit_transform(classification_X)\n",
    "classification_X_processed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_X_train, classification_X_test, classification_y_train, classification_y_test = train_test_split(\n",
    "    classification_X_processed,\n",
    "    classification_y,\n",
    "    test_size=0.2,\n",
    "    random_state=1,\n",
    "    shuffle=True,\n",
    "    stratify=classification_y #Ensure train set and test set have the same\n",
    "    # ratio for the 2 categories\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "svc_centroid = SVC(\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "svc_centroid_grid_search = GridSearchCV(\n",
    "    estimator=svc_centroid,\n",
    "    param_grid={\n",
    "        # 'C': [0.001, 0.01, 0.1, 1, 10, 100], #Regularization parameter\n",
    "        'kernel': ['rbf'], #Algorithm kernel. Should add poly and sigmoid\n",
    "        #'degree': [2,3,4], #Polynomial degree\n",
    "        'gamma': [0.1, 0.5] #Coefficient for algorithms\n",
    "    },\n",
    "    cv=RepeatedStratifiedKFold(\n",
    "        n_splits=3,\n",
    "        n_repeats=2, #Each time the split will be different\n",
    "        random_state=1\n",
    "    ),\n",
    "    scoring={\n",
    "        'Recall': make_scorer(\n",
    "            recall_score, #Need pos_label\n",
    "            pos_label='BBB+', #Without this, pos_label is default to be 1\n",
    "            # and will through an error since 1 isn't \"BBB+\" or \"BBB-\"\n",
    "            average='binary'\n",
    "        ),\n",
    "        'Precision': make_scorer(\n",
    "            precision_score, #Need pos_label\n",
    "            pos_label='BBB+',\n",
    "            average='binary'\n",
    "        ),\n",
    "        'F1': make_scorer(\n",
    "            f1_score, #Need pos_label\n",
    "            pos_label='BBB+',\n",
    "            average='binary'\n",
    "        ),\n",
    "        'Accuracy': 'accuracy', #accuracy_score doesn't need pos_label\n",
    "        'Balanced accuracy': 'balanced_accuracy',\n",
    "        'AUROC': 'roc_auc'\n",
    "    },\n",
    "    refit='AUROC',\n",
    "\n",
    "    n_jobs=1,\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "svc_centroid_grid_search.fit(classification_X_train, classification_y_train)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('GridSearchCV took {}'.format(end_time - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svc_centroid_results_df = pd.DataFrame(svc_centroid_grid_search.cv_results_)\n",
    "#Make the GridSearch results into a df\n",
    "\n",
    "svc_centroid_results_df.drop(\n",
    "    list(svc_centroid_results_df.filter(regex='time|split|std')),\n",
    "    axis=1,\n",
    "    inplace=True\n",
    ")  # Remove columns that aren't very interesting\n",
    "svc_centroid_results_df = svc_centroid_results_df.sort_values(\n",
    "    by='rank_test_AUROC')\n",
    "\n",
    "svc_centroid_results_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svc_centroid_results_df.to_csv(\n",
    "    r'model_grid_search\\svc_centroid_classifier\\results.csv',\n",
    "    index=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_svc_centroid_classifier = svc_centroid_grid_search.best_estimator_\n",
    "save_pickle(\n",
    "    best_svc_centroid_classifier,\n",
    "    r'model_pickles\\svc_centroid_classifier\\best_svc_centroid_classifier.pkl'\n",
    ")\n",
    "# To load this best model again, use load_pickle(r'model_pickles\\svc_centroid_classifier\\best_svc_centroid_classifier.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Balanced by SMOTEENN method"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_smoteenn_df = pd.read_csv(\n",
    "    r\"datasets/balanced_datasets/BBB_classification_balanced_smoteenn.csv.zip\"\n",
    ")\n",
    "\n",
    "classification_smoteenn_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data pre-processing\n",
    "\n",
    "classification_X = classification_smoteenn_df.loc[\n",
    "                   :,\n",
    "                   ~classification_smoteenn_df.columns.isin(\n",
    "                       ['SMILES', 'BBB+/BBB-'])\n",
    "                   ]\n",
    "\n",
    "classification_y = classification_smoteenn_df['BBB+/BBB-']\n",
    "\n",
    "\n",
    "data_processing_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(\n",
    "        n_components=0.95, #When using the svd_solver='full', n_components\n",
    "        # can be between 0 and 1 to represent the percentage of variance\n",
    "        # that you want to explain\n",
    "        svd_solver='full'\n",
    "    ))\n",
    "])\n",
    "\n",
    "classification_X_processed=data_processing_pipeline.fit_transform(classification_X)\n",
    "classification_X_processed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_X_train, classification_X_test, classification_y_train, classification_y_test = train_test_split(\n",
    "    classification_X_processed,\n",
    "    classification_y,\n",
    "    test_size=0.2,\n",
    "    random_state=1,\n",
    "    shuffle=True,\n",
    "    stratify=classification_y #Ensure train set and test set have the same\n",
    "    # ratio for the 2 categories\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "svc_smoteenn = SVC(\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "svc_smoteenn_grid_search = GridSearchCV(\n",
    "    estimator=svc_smoteenn,\n",
    "    param_grid={\n",
    "        # 'C': [0.001, 0.01, 0.1, 1, 10, 100], #Regularization parameter\n",
    "        'kernel': ['rbf'], #Algorithm kernel. Should add poly and sigmoid\n",
    "        #'degree': [2,3,4], #Polynomial degree\n",
    "        'gamma': [0.1, 0.5] #Coefficient for algorithms\n",
    "    },\n",
    "    cv=RepeatedStratifiedKFold(\n",
    "        n_splits=3,\n",
    "        n_repeats=2, #Each time the split will be different\n",
    "        random_state=1\n",
    "    ),\n",
    "    scoring={\n",
    "        'Recall': make_scorer(\n",
    "            recall_score, #Need pos_label\n",
    "            pos_label='BBB+', #Without this, pos_label is default to be 1\n",
    "            # and will through an error since 1 isn't \"BBB+\" or \"BBB-\"\n",
    "            average='binary'\n",
    "        ),\n",
    "        'Precision': make_scorer(\n",
    "            precision_score, #Need pos_label\n",
    "            pos_label='BBB+',\n",
    "            average='binary'\n",
    "        ),\n",
    "        'F1': make_scorer(\n",
    "            f1_score, #Need pos_label\n",
    "            pos_label='BBB+',\n",
    "            average='binary'\n",
    "        ),\n",
    "        'Accuracy': 'accuracy', #accuracy_score doesn't need pos_label\n",
    "        'Balanced accuracy': 'balanced_accuracy',\n",
    "        'AUROC': 'roc_auc'\n",
    "    },\n",
    "    refit='AUROC',\n",
    "\n",
    "    n_jobs=1,\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "svc_smoteenn_grid_search.fit(classification_X_train, classification_y_train)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('GridSearchCV took {}'.format(end_time - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svc_smoteenn_results_df = pd.DataFrame(svc_smoteenn_grid_search.cv_results_)\n",
    "#Make the GridSearch results into a df\n",
    "\n",
    "svc_smoteenn_results_df.drop(\n",
    "    list(svc_smoteenn_results_df.filter(regex='time|split|std')),\n",
    "    axis=1,\n",
    "    inplace=True\n",
    ")  # Remove columns that aren't very interesting\n",
    "svc_smoteenn_results_df = svc_smoteenn_results_df.sort_values(\n",
    "    by='rank_test_AUROC')\n",
    "\n",
    "svc_smoteenn_results_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svc_smoteenn_results_df.to_csv(\n",
    "    r'model_grid_search\\svc_smoteenn_classifier\\results.csv',\n",
    "    index=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_svc_smoteenn_classifier = svc_smoteenn_grid_search.best_estimator_\n",
    "save_pickle(\n",
    "    best_svc_smoteenn_classifier,\n",
    "    r'model_pickles\\svc_smoteenn_classifier\\best_svc_smoteenn_classifier.pkl'\n",
    ")\n",
    "# To load this best model again, use load_pickle(r'model_pickles\\svc_smoteenn_classifier\\best_svc_smoteenn_classifier.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
